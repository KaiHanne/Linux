#!/bin/bash
# ==================================================================================================
#
#      File: save_ca_stats
#      Date: Mon Nov 11 09:33:13 CET 2019
#      What: save cloud adapter statics from /var/log/cloudadapter/tunnel.log to a specified SQL file
#            for loading in a PostgreSQl database.
#       Who: Gert J. Willems
#
# -------------------------------------------------------------------------------------------------- 
# record: 
#       213.52.178.108 - - [03/Dec/2019:07:40:06 +0100] "POST /bag HTTP/2.0" 200 38
#       1                  4                            5     6              8   9
#       ipaddress          timestamp         http_request     soort  http_status http_
# -------------------------------------------------------------------------------------------------- 
#
# ==================================================================================================
# History:
# Date       Rev   Author        What
# ---------- ----- ------------- -------------------------------------------------------------------
# 11-11-2019 0.1   gjwillems     created
# 07-01-2020 0.2   gjwillems     quiet option added.
# 20-01-2020 0.3   gjwillems     -l option added : determins the last saved (rotated) tunnel.log 
#                                file, creates an insert file and loads the records in the 
#                                brmo_staging database.
# 22-01-2020 0.4   gjwillems     weeknumber for generated file changed to day-of-the-year
#                                output write function added; some minor improvements
# 23-01-2020 0.5   gjwillems     logdir added filenames modified consistent
# 05-02-2020 0.6   gjwillems     BUGFIX: ambiguous redirect solved 'dmlfile' declare mover outside
#                                the 'if'; some minor cosmetic changes
# 05-02-2020 0.7   gjwillems     configural variables/parameters moved to save_ca_stats.conf
# 19-10-2020 0.8   gjwillems     BUG PRV-2010 3296-01 solved: added check if $ipaddress is null
#                                    PRV-2010 3296-02 solved: empty printf statement resuls in:
#                                    "printf: usage: printf [-v var] format [arguments]"
#    
# ==================================================================================================
# set -xv
# --------------------------------------------------------------------------------------------------
mod=$(basename ${0})
path=$(dirname ${0})
rev="0.7"
rev_date="Wed Feb  5 15:32:04 CET 2020"

# local settings
nano=2
quiet=0
fflg=0
p_timestamp="01/Jan/1970:00:00:00.00+0100"
add=0
loadsql=0
use_last=0

source "/usr/local/bin/${mod}.conf"

# ================================================================================================== 
# usage
# -------------------------------------------------------------------------------------------------- 
function usage () {
   cat << EOH
  
   ${mod} revision ${rev} build ${rev_date}

   ${mod} usage.

   ${mod} create insert statements from the tunnel_log file to save statistical information 
   of the Cloud Adapter.

   -h this help page
   -f inputfile (default tunnel_log)
   -c <file>  create file with insert statement instead of direct loading
   -q quiet operation
   -l create an insert file based on the last rotated tunnel.log and loads this into the database
   -L load directly into the database instaed of save it to file only

EOH
 
   exit 1
}

# ================================================================================================== 
# simple output function
# -------------------------------------------------------------------------------------------------- 
function write () {
   local _self_="${FUNCNAME[0]}"
   message="${1}"
   type="${2}" 
   ts=$(date +"%Y%m%d%H%M%S")
   printf "%s %s %s - %s\\n" "${ts}" "${mod}" "${type:-INFO}" "${message}"
   return 0
}

# ==================================================================================================
# load_file
# load the specified file into the database
# inputfile = generated file with INSERT statements
# outputfile = same as inputfile but with the extension .log
# recs is the nummber of records to process
# --------------------------------------------------------------------------------------------------
function load_file() {
   local _self_="${FUNCNAME[0]}"
   
   inputfile="${1}"
   recs="${2}"
   outputfile="$(echo ${1}|sed 's/sql/log/g')"

   write "${_self_}() inputfile=[${inputfile}] outputfile=[${outputfile}]"

   inserts=$(cat ${inputfile} | grep ^INSERT | wc -l)
   if [ ${inserts:-0} -eq ${recs:-1} ]; then
      write "OK to load the SQL file ${inputfile} ..."
      write "${inserts} records to insert in the ${dbname} database"
      write "exec: ${psql} ${dbname} -f ${inputfile} -L ${outputfile}"

      ${psql} ${DBNAME} -f ${inputfile} -L ${outputfile}

   else
      write "check the SQL file, tunnel_log records=[${recs}] SQL file inserts=[${inserts}]"
   fi
   exit 0
}

# ==================================================================================================
# Debug
# --------------------------------------------------------------------------------------------------
if [ ${SCRIPT_DEBUG} -eq 2 ]; then
   exec 5> ${debug_log} 
   BASH_XTRACEFD="5"
   PS4='> DBG> $LINENO: '
   set -x
fi

function debug() {
   local _self_="${FUNCNAME[0]}"
   [[ ${SCRIPT_DEBUG} -eq 0 ]] && return
   local message="${1}"
   write ">>> ${message}" "DBG"
}

# ==================================================================================================
# commandline parser
# -f use this specific file to process !including path
# -q do not show the generated insert statements
# -c overrule the default output SQL file
# -a add record for record into the database
# -l use the last rotated log file: tricky because it depends on the schedule of the logrotate 
#    action and the moment this script is scheduled....
# -L load the generated file into the database 
# ------------------------------------------------------------------------------------------------
while getopts "f:hc:qLal" argv
do
   case ${argv} 
   in
      h) usage ;;
      f) tunnel_log="${OPTARG}"
         fflg=1 ;;
      c) dmlfile="${OPTARG}" ;;
      q) quiet=1 ;;
      a) add=1 ;;
      l) use_last=1 ;;
      L) loadsql=1 ;;
   esac
done

# Determine the Insert filename based on the weeknumber 
#[[ ! -s ${tunnel_log} ]] && write "File [${tunnel_log}] not found" && exit 1

date=$(date +"%j")
[[ ${fflg} -eq 1 ]] && dd=$(echo ${tunnel_log} | cut -d '-' -f2) \
                    && date=$(date -d "${dd}" +"%j")

# dmlfile="${logdir}/${date}_insert_ca_stats_$(whoami).sql"

# ==================================================================================================
# Debug
# --------------------------------------------------------------------------------------------------
function add_record() {
   local _self_=${FUNCNAME[0]}
   ${psql} ${dbname} -c "${record}"
}

# ====== main scope ================================================================================
main () {
   # set -xv
   local _self_="${FUNCNAME[0]}"

   write "start save Cloud Adapter statistics collected in the tunnel log file"

   [[ -z ${dmlfile} ]] && dmlfile="${logdir}/${date}_insert_ca_stats_$(whoami).sql"

   # if "use last" then run this script with the specified switches
   if [ ${use_last} -eq 1 ]; then
      if [ -f ${last_rotated_tunnel_log} ]; then
         write "using last rotated tunnel log file [${last_rotated_tunnel_log}]"
         write "output (SQL) can be found in [${dmlfile}]"

         rec=$(cat ${last_rotated_tunnel_log}|wc -l)
         ${path}/${mod} -q -f ${last_rotated_tunnel_log} 

         load_file "${dmlfile}" "${rec:-0}"
      else
         write "file not found [${last_rotated_tunnel_log}]"
         exit 2
      fi 
   fi

   printf "BEGIN TRANSACTION ISOLATION LEVEL READ COMMITTED;\n" > ${dmlfile}

   [[ ! -s "${tunnel_log}" ]] && write "input file ${tunnel_log} not found" "ERROR" \
                           && exit 1

   [[ ${fflg} -eq 1 ]] && write "processing file [${tunnel_log}]"

   rec=$(cat ${tunnel_log}|wc -l)
   records=0

   if [ ${quiet} -eq 1 ]; then
      write "Processing ${rec} records."
      write "This may take a few minutes..."
   fi

   # ----------------------------------------------------
   # loop through the tunnel log file and create INSERT 
   # statements. The sort is not working properly
   # but is still there (2be improved).
   cat ${tunnel_log}| sort --key=21,40 | while read line
   do 
      # create the array ....
      IFS=', ' read -r -a array <<< "${line}"

      # Solved: BUG-PRV-2010_3296-02
      c_timestamp="$(printf ${array[3]}${array[4]:-0} | sed 's/\[//g'| sed 's/\]//g')"

      debug "current timestamp=[${c_timestamp}] previous timestamp = [${p_timestamp}]"

      if [ "${c_timestamp}" == "${p_timestamp}" ];  then
         timestamp=$(printf "${array[3]}.%-2.2d ${array[4]}" ${nano} | sed 's/\[//g'| sed 's/\]//g')
         debug "TS EQ >> new timestamp: [${timestamp}]"
         ((nano+=1))
         [[ ${nano} -eq 99 ]] && nano=2
      else
         timestamp=$(printf "${array[3]}.01 ${array[4]}" | sed 's/\[//g'| sed 's/\]//g')
         debug "TS UNIQUE >> new timestamp: [${timestamp}]"
         nano=2
      fi

      #   printf "DEBUG >>>> %s\n" "${line}"; 
      #printf "timestamp = ${timestamp}\n"
      #printf "p_timestamp = ${p_timestamp}\n"
      #printf "c_timestamp = ${c_timestamp}\n"
   
      ipaddress="${array[0]}"
      http_request="${array[5]:1}"
      soort="${array[6]:1:3}"
      http_status="${array[8]}"
      http_result="${array[9]}"
   
      # Solved: BUG-PRV-2010_3296-01
      [[ "${ipaddress}" = "" ]] && debug "ipaddress value is null!" && continue 

      record="INSERT INTO cloud_adapter_statistics ( ipaddress, aflever_datum, soort, http_status, http_request, http_result )
              VALUES ('${ipaddress}','${timestamp}','${soort}','${http_status}','${http_request}','${http_result}');"
   
      ((records+=1))

      if [ ${quiet} -eq 0 ]; then
         printf "${record} rec[${records}/${rec}]\n\n"
      fi

      if [ ! -z "${dmlfile}" ]; then
         printf "${record}\n" >> ${dmlfile}
      else
         [[ ${add} -eq 1 ]] && add_record 
      fi

      p_timestamp="${c_timestamp}"
   done

   # the transaction should be commited at this point, except when an error occurs, the commit will not succeed
   printf "COMMIT;\n" >> ${dmlfile}  
  
   if [ ${loadsql} -eq 1 ]; then
      load_file "${dmlfile}" "${rec}"
   fi

   if [ ! -z ${dmlfile} ]; then
      write "DML File creation done: [${dmlfile}],"
   fi

}

main

# IFS=$'\r\n' GLOBIGNORE='*' command eval  'datelist=($(cat ${dates}))'
